{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_SOTA_CNNs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df81a81e46f14390b13638a1bdc0b2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4826bc3d2155440898865a236551f9f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe37ccf6fd7d447aa8b4f993cf865fcb",
              "IPY_MODEL_4af63d3ebb154569b82b61503b2a6379"
            ]
          }
        },
        "4826bc3d2155440898865a236551f9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe37ccf6fd7d447aa8b4f993cf865fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1f6c84ac0a74f06a561c610ea8fd545",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36022dab8b1d472d86de0a2cf27b65f6"
          }
        },
        "4af63d3ebb154569b82b61503b2a6379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_161fff4a6295448f9ad461db7825cf65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:05&lt;00:00, 28937051.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1933d8dbc43b4566ab81391035c2c51b"
          }
        },
        "e1f6c84ac0a74f06a561c610ea8fd545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36022dab8b1d472d86de0a2cf27b65f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "161fff4a6295448f9ad461db7825cf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1933d8dbc43b4566ab81391035c2c51b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKf3hMtj7FAM"
      },
      "source": [
        "# Training SOTA CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUj3MYU9_ro0"
      },
      "source": [
        "## Quickvision + PyTorch Image Models CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCpx431M7Lnb"
      },
      "source": [
        "- A Huge home to SOTA CNNs is [PyTorch Image Models](https://github.com/rwightman/pytorch-image-models) by Ross Wightman.\n",
        "\n",
        "- It has high quality models with ImageNet weights.\n",
        "\n",
        "- Let's train these for Trasnfer Learning Tasks !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzje_vFe38vG"
      },
      "source": [
        "# Install PyTorch Image Models\n",
        "! pip install -q timm\n",
        "! pip install -q git+https://github.com/Quick-AI/quickvision.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huQbbLhe88I-"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rATi1sUo7wcd"
      },
      "source": [
        "- A List of PreTrained Models Provided By Timm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFnhabxj7ouW"
      },
      "source": [
        "import timm\n",
        "from pprint import pprint\n",
        "model_names = timm.list_models(pretrained=True)\n",
        "pprint(model_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFQY4e7Y78UG"
      },
      "source": [
        "- Let's stick to EfficientNet and Train it !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PW-69Dr8eUT"
      },
      "source": [
        "## CIFAR10 Dataset and Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIaAXS3E8kcG"
      },
      "source": [
        "- We use CIFAR10 Dataset to train on.\n",
        "- It is directly available in torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFtw5zad8xZg"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 512  # Training Batch Size\n",
        "VALID_BATCH_SIZE = 512  # Validation Batch Size"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHGAc97A8guE"
      },
      "source": [
        "train_transforms = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])\n",
        "valid_transforms = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "df81a81e46f14390b13638a1bdc0b2cd",
            "4826bc3d2155440898865a236551f9f0",
            "fe37ccf6fd7d447aa8b4f993cf865fcb",
            "4af63d3ebb154569b82b61503b2a6379",
            "e1f6c84ac0a74f06a561c610ea8fd545",
            "36022dab8b1d472d86de0a2cf27b65f6",
            "161fff4a6295448f9ad461db7825cf65",
            "1933d8dbc43b4566ab81391035c2c51b"
          ]
        },
        "id": "18T4jW3X8un8",
        "outputId": "ac260e7d-eb08-424a-9cf9-5ee5cb120c5f"
      },
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\"./data\", download=True, train=True, transform=train_transforms)\n",
        "valid_dataset = torchvision.datasets.CIFAR10(\"./data\", download=True, train=False, transform=valid_transforms)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df81a81e46f14390b13638a1bdc0b2cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCORWrr8wSQ"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, VALID_BATCH_SIZE, shuffle=False)\n",
        "VALID_BATCH_SIZE = 512  # Validation Batch Size"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1zu7uIU7_t9"
      },
      "source": [
        "## Train EfficientNet from PyTorch Image Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdvAXZyD777s"
      },
      "source": [
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=10, in_chans=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1QxEm19l8b"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcSZOVCX9OtK"
      },
      "source": [
        "### Here is where you can use Quickvision's Training Recipe to train these models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8SAyvBv908V",
        "outputId": "023d69e4-188f-4f63-a495-06d5b8cc6654"
      },
      "source": [
        "from quickvision.models.classification import cnn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcK5nVqd95fk"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_zIW9yD70uj",
        "outputId": "ea6e1f52-535b-4fc0-b290-02f0b5c25520"
      },
      "source": [
        "history = cnn.fit(model=model, epochs=2, train_loader=train_loader,\n",
        "                  val_loader=valid_loader, criterion=criterion, device=device,\n",
        "                  optimizer=optimizer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Epoch = 0\n",
            "Batch Train Time: 0.522 (0.522)  Loss:  7.6988 (7.6988)  Top 1 Accuracy: 10.5469 (10.5469)  Top 5 Accuracy: 51.5625 (51.5625)\n",
            "Batch Train Time: 0.143 (0.200)  Loss:  1.1475 (2.0493)  Top 1 Accuracy: 61.6071 (45.3340)  Top 5 Accuracy: 95.5357 (87.4720)\n",
            "Time taken for train step = 19.60645031929016 sec\n",
            "\n",
            "Validating Epoch = 0\n",
            "Batch Inference Time: 0.111 (0.111)  Loss:  1.1467 (1.1467)  Top 1 Accuracy: 58.2031 (58.2031)  Top 5 Accuracy: 96.2891 (96.2891)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1/2 [00:32<00:32, 32.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch Inference Time: 0.074 (0.115)  Loss:  1.3251 (1.1606)  Top 1 Accuracy: 51.1029 (60.1800)  Top 5 Accuracy: 95.5882 (95.9100)\n",
            "Finished the validation epoch\n",
            "Time taken for validation step = 2.2983126640319824 sec\n",
            "Done Training, Model Saved to Disk\n",
            "\n",
            "Training Epoch = 1\n",
            "Batch Train Time: 0.222 (0.222)  Loss:  1.0024 (1.0024)  Top 1 Accuracy: 66.4062 (66.4062)  Top 5 Accuracy: 96.4844 (96.4844)\n",
            "Batch Train Time: 0.162 (0.198)  Loss:  0.8628 (0.8909)  Top 1 Accuracy: 71.4286 (69.1740)  Top 5 Accuracy: 97.3214 (97.5800)\n",
            "Time taken for train step = 19.38525390625 sec\n",
            "\n",
            "Validating Epoch = 1\n",
            "Batch Inference Time: 0.133 (0.133)  Loss:  0.9281 (0.9281)  Top 1 Accuracy: 70.1172 (70.1172)  Top 5 Accuracy: 97.8516 (97.8516)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:53<00:00, 26.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch Inference Time: 0.069 (0.120)  Loss:  1.0122 (0.8934)  Top 1 Accuracy: 62.5000 (69.4400)  Top 5 Accuracy: 98.1618 (97.7600)\n",
            "Finished the validation epoch\n",
            "Time taken for validation step = 2.3908989429473877 sec\n",
            "Done Training, Model Saved to Disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfKi7CBV_NHT"
      },
      "source": [
        "- In return you get a Keras Like History Dictionary.\n",
        "- It keeps a track of Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8NSvBgJ_MZE",
        "outputId": "f1775c78-d5e3-4e70-b2b8-a832d26fa4ad"
      },
      "source": [
        "pprint(history)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': {'loss': [2.049303819618225, 0.8909260382080079],\n",
            "           'top1_acc': [45.33400000366211, 69.17400001464844],\n",
            "           'top5_acc': [87.47199999267578, 97.58000003662109]},\n",
            " 'val': {'loss': [1.1606252620697022, 0.8934034944534301],\n",
            "         'top1_acc': [60.17999995727539, 69.44],\n",
            "         'top5_acc': [95.90999996337891, 97.7600000366211]}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKRZHf0m-Hrp"
      },
      "source": [
        "- You can also get a granular control over these using `train_step`, `val_step` methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3RpTv5293km",
        "outputId": "0aad4958-8a33-4b34-da87-16587d9f9c2e"
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print()\n",
        "    print(f\"Training Epoch = {epoch}\")\n",
        "    train_metrics = cnn.train_step(model, train_loader, criterion, device, optimizer)\n",
        "    print()\n",
        "\n",
        "    print(f\"Validating Epoch = {epoch}\")\n",
        "    valid_metrics = cnn.val_step(model, valid_loader, criterion, device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Epoch = 0\n",
            "Batch Train Time: 0.326 (0.326)  Loss:  0.6633 (0.6633)  Top 1 Accuracy: 78.1250 (78.1250)  Top 5 Accuracy: 99.0234 (99.0234)\n",
            "Batch Train Time: 0.135 (0.200)  Loss:  0.7350 (0.6222)  Top 1 Accuracy: 74.4048 (78.3520)  Top 5 Accuracy: 99.4048 (98.9080)\n",
            "Time taken for train step = 19.601767778396606 sec\n",
            "\n",
            "Validating Epoch = 0\n",
            "Batch Inference Time: 0.109 (0.109)  Loss:  0.7944 (0.7944)  Top 1 Accuracy: 72.2656 (72.2656)  Top 5 Accuracy: 98.4375 (98.4375)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1/2 [00:21<00:21, 21.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch Inference Time: 0.071 (0.114)  Loss:  0.8842 (0.8489)  Top 1 Accuracy: 68.0147 (71.6100)  Top 5 Accuracy: 98.5294 (97.9200)\n",
            "Finished the validation epoch\n",
            "Time taken for validation step = 2.2907419204711914 sec\n",
            "\n",
            "Training Epoch = 1\n",
            "Batch Train Time: 0.231 (0.231)  Loss:  0.4109 (0.4109)  Top 1 Accuracy: 86.5234 (86.5234)  Top 5 Accuracy: 99.8047 (99.8047)\n",
            "Batch Train Time: 0.139 (0.201)  Loss:  0.5512 (0.4279)  Top 1 Accuracy: 82.1429 (85.1920)  Top 5 Accuracy: 99.7024 (99.5020)\n",
            "Time taken for train step = 19.730385780334473 sec\n",
            "\n",
            "Validating Epoch = 1\n",
            "Batch Inference Time: 0.111 (0.111)  Loss:  0.8637 (0.8637)  Top 1 Accuracy: 72.4609 (72.4609)  Top 5 Accuracy: 98.8281 (98.8281)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:43<00:00, 21.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch Inference Time: 0.068 (0.115)  Loss:  0.8986 (0.8965)  Top 1 Accuracy: 70.2206 (73.1100)  Top 5 Accuracy: 98.1618 (97.8400)\n",
            "Finished the validation epoch\n",
            "Time taken for validation step = 2.298086404800415 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1A2341f_dVv"
      },
      "source": [
        "- Again, quickvision computes metrics for you !\n",
        "- You can print them to have look !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Xq4Ums_WMk",
        "outputId": "c96f87c6-7e23-4250-c7e5-c28aa47273ca"
      },
      "source": [
        "pprint(train_metrics)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('loss', 0.42793877683639525),\n",
            "             ('top1', 85.19200002197266),\n",
            "             ('top5', 99.50200002685547)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38YWwxFy_hL_",
        "outputId": "7d838c2c-6657-4d61-ec19-7527995f9710"
      },
      "source": [
        "pprint(valid_metrics)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('loss', 0.8965282435417176),\n",
            "             ('top1', 73.11000001220702),\n",
            "             ('top5', 97.84000003662109)])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}